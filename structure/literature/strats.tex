\subsection{\gls*{ae} aptikimo strategijos}\label{sec:literature:defense}

\def\strat{\Gls{adverasrialRetraining}}
\subsubsection{\Gls*{adverasrialRetraining}}\label{sec:literature:defense:retraining}

\strat~\angl{adversarial retraining} -- tai papildomas \gls{ml} modelio mokymo etapas. Tarkime pradinis išmokytas \gls{ml} modelis yra $M_1$. Tuomet \gls{adverasrialRetraining} yra \gls{ae} generavimas atakuojant $M_1$ ir šio modelio papildomas mokymas su sugeneruotais \gls{ae}. Po mokymo gauname $M_2 \; (M_1 \xrightarrow{AE} M_2)$, kuris bus atsparesnis \glsplkam{adversarial}. Ši strategija nėra atspari \glsplkam{blackBoxAttack} \cite{chakrabortySurveyAdversarialAttacks2021}.



\def\strat{Gradientų slėpimas}
\subsubsection{\strat}

\strat~\angl{gradient hiding} -- tai metodas, kai pasirenkama klasifikatoriaus architektūra, kurioje nefigūruoja gradientai, pavyzdžiui, nediferencijuojami modeliai, tokie kaip atsitiktinis miškas \angl{random forest}. Dėl \gls{ae} perkeliamumo \poskyris{sec:literature:transfer} ši strategija yra neveiksminga prieš \glsplka{blackBoxAttack} \cite{chakrabortySurveyAdversarialAttacks2021}.



\def\strat{Kategorijų švelninimas}
\subsubsection{\strat}

\strat~\angl{label smoothing} -- metodas, leidžiantis geriau klasifikuoti nežinomus duomenis ir taip apsisaugoti nuo \glsplko{adversarial}. \strat~reiškia tiksliai apibrėžtų kategorijų \angl{hard labels} pavertimą tikimybiniais vektoriais \angl{soft labels}. Tuomet \gls{ml} modelio išvestis (taip pat tikimybinis vektorius) gali būti palyginama su kategorijų vektoriais taikant norimas euristikas, pavyzdžiui, kosinusų panašumą \angl{cosine similarity}. Dėl \gls{ae} perkeliamumo \poskyris{sec:literature:transfer} ši strategija neveiksminga prieš \glsplka{blackBoxAttack} \cite{chakrabortySurveyAdversarialAttacks2021}.



\def\strat{Perkeliamumo blokavimas}
\subsubsection{\strat}\label{sec:literature:defense:blocking}

\strat~\angl{transferability blocking} -- tai \glsko{adverasrialRetraining} \skyrius{sec:literature:defense:retraining} praplėtimas, įtraukiant naują (\textit{NULL}) kategoriją į galimas klasifikatoriaus išvestis. Ši strategija praplečia klasifikatoriaus mokymą į šiuos etapus:
\begin{enumerate}
    \item Įprastas klasifikatoriaus mokymas.
    \item \textit{NULL} tikimybių funkcijos $f$ skaičiavimas. $p_{NULL}$ suprantama kaip \glsko{adversarial} tikimybė. \textit{NULL} tikimybių ir jų skaičiavimo funkcijos $f$ ryšys pateiktas \ref{eq:null}-oje lygtyje.
    \item \Gls{adverasrialRetraining}, įtraukiant tiek originalias įvestis, tiek perturbuotas ($\delta X$).
\end{enumerate}

Ši strategija sprendžia pagrindinį daugelio kitų strategijų trūkumą -- \gls{ae} perkeliamumą \poskyris{sec:literature:transfer}, todėl yra pakankamai efektyvi \cite{chakrabortySurveyAdversarialAttacks2021}.

\begin{equation}\label{eq:null}
    \begin{split}
        &p_{NULL} = f\left(\frac{\| \delta X \|_0}{\|X\|}\right),\\
        \text{čia}\; \| \delta
        &X \|_0 \sim U[1,\; N_{max}], \; N_{max} = \min n \ni f\left(\frac{n}{\|X\|}\right)
        = 1
    \end{split}
\end{equation}



\def\strat{Bazės keitimas, transformacijos}
\subsubsection{\strat}\label{sec:literature:defense:basis}

\strat~\angl{change of basis, transformations} -- tai strategija transformuojanti duomenis juos projektuojant kitoje koordinačių sistemoje. Pavyzdžiui, \gls{pca} metodas keičia duomenų koordinačių sistemos bazę taip, jog pirma komponentė turėtų didžiausią \glska{inertia}. Tam tikrais atvejais taikant šią strategiją gali būti prarandama informacija (jei keičiama į mažesnės dimensijos bazę), pavyzdžiui, naudojant \textit{JPEG lossy compression} algoritmą nuotraukų transformacijai. Ši strategija padeda efektyviai apsisaugoti nuo visų tipų \glsplko{adversarial} \cite{chakrabortySurveyAdversarialAttacks2021}.